{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "from lenet import LeNet, get_activations\n",
    "from heatmap import compute_heatmap, display_heatmap, cka_linear\n",
    "from loaders import get_mnist_loaders\n",
    "from prune import cka_structured\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for _, (batch_x, batch_y) in enumerate(loader):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        pred_y = torch.argmax(model(batch_x), axis=-1)\n",
    "        correct += torch.sum(torch.eq(pred_y, batch_y))\n",
    "    return (correct / len(loader.dataset)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cka_structured_all(model, module, data, cka_threshold=None): # 0.995\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = {\"cka\": [], \"val_acc\": [], \"pruned\": []}\n",
    "\n",
    "        org_weight = torch.clone(module.weight)\n",
    "        _, val_loader = get_mnist_loaders(60)\n",
    "\n",
    "        neurons = module.weight.shape[0]\n",
    "        for i in range(neurons):\n",
    "            module, pruned, ckas = cka_structured(\n",
    "                model, module, 'weight', data, n=1, verbose=True)\n",
    "            val_acc = compute_acc(model, val_loader)\n",
    "\n",
    "            result[\"cka\"].append(ckas[0])\n",
    "            result[\"pruned\"].append(pruned[0])\n",
    "            result[\"val_acc\"].append(val_acc)\n",
    "\n",
    "            print(f\"Pruned neuron {pruned[0]} with CKA = {ckas[0]}, val_acc = {val_acc} and p = {(i + 1) / neurons}\")\n",
    "            if cka_threshold is not None and ckas[0] < cka_threshold:\n",
    "                break\n",
    "        \n",
    "        module.weight[:, :] = org_weight\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_structured_all(model, module, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = {\"cka\": [], \"val_acc\": [], \"pruned\": []}\n",
    "\n",
    "        act = get_activations(model, data)\n",
    "        neuron_order = torch.argsort(torch.linalg.vector_norm(torch.clone(module.weight), ord=1, dim=-1))\n",
    "\n",
    "        neurons = module.weight.shape[0]\n",
    "        for i in range(neurons):\n",
    "            prune.ln_structured(module, 'weight', amount=1, n=1, dim=0)\n",
    "\n",
    "            pruned_act = get_activations(model, data)\n",
    "            _, val_loader = get_mnist_loaders(60)\n",
    "            val_acc = compute_acc(model, val_loader)\n",
    "            cka = cka_linear(act[module], pruned_act[module])\n",
    "\n",
    "            result[\"cka\"].append(cka)\n",
    "            result[\"pruned\"].append(neuron_order[i].item())\n",
    "            result[\"val_acc\"].append(val_acc)\n",
    "\n",
    "            print(f\"Pruned with L1 norm with CKA = {cka}, val_acc = {val_acc} and p = {(i + 1) / neurons}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_rates = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for FC0_PRUNE_RATE in prune_rates:\n",
    "    for FC1_PRUNE_RATE in prune_rates:\n",
    "        DROPOUT_RATE = 0.5\n",
    "        DROPOUT_RATE_STR = str(int(DROPOUT_RATE * 100)).zfill(2)\n",
    "        FC0_PRUNE_RATE_STR = str(int(FC0_PRUNE_RATE * 100)).zfill(2)\n",
    "        FC1_PRUNE_RATE_STR = str(int(FC1_PRUNE_RATE * 100)).zfill(2)\n",
    "\n",
    "        print(f\"FC0_PRUNE_RATE = {FC0_PRUNE_RATE}, FC1_PRUNE_RATE = {FC1_PRUNE_RATE}\")\n",
    "\n",
    "        results = []\n",
    "        for i in range(30):\n",
    "            \n",
    "            # Load model.\n",
    "            model = LeNet('0d', DROPOUT_RATE)\n",
    "            model_path = f\"models/lenet-0d-{DROPOUT_RATE_STR}-{i}.model\"\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "            # Prune with CKA.\n",
    "            train_loader, val_loader = get_mnist_loaders(60)\n",
    "            data = next(iter(train_loader))[0].to(device)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                _, fc0_neurons, fc0_ckas = cka_structured(model, model.fc0, 'weight', data, p=FC0_PRUNE_RATE, verbose=True)\n",
    "                _, fc1_neurons, fc1_ckas = cka_structured(model, model.fc1, 'weight', data, p=FC1_PRUNE_RATE, verbose=True)\n",
    "                val_acc = compute_acc(model, val_loader)\n",
    "            \n",
    "            fc0_fc1_result = {\n",
    "                \"fc0\": {\"pruned\": fc0_neurons, \"cka\": fc0_ckas},\n",
    "                \"fc1\": {\"pruned\": fc1_neurons, \"cka\": fc1_ckas},\n",
    "                \"val_acc\": val_acc,\n",
    "            }\n",
    "\n",
    "            # Reload model.\n",
    "            model = LeNet('0d', DROPOUT_RATE)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                _, fc1_neurons, fc1_ckas = cka_structured(model, model.fc1, 'weight', data, p=FC1_PRUNE_RATE, verbose=True)\n",
    "                _, fc0_neurons, fc0_ckas = cka_structured(model, model.fc0, 'weight', data, p=FC0_PRUNE_RATE, verbose=True)\n",
    "                val_acc = compute_acc(model, val_loader)\n",
    "\n",
    "            fc1_fc0_result = {\n",
    "                \"fc0\": {\"pruned\": fc0_neurons, \"cka\": fc0_ckas},\n",
    "                \"fc1\": {\"pruned\": fc1_neurons, \"cka\": fc1_ckas},\n",
    "                \"val_acc\": val_acc,\n",
    "            }\n",
    "\n",
    "            # Update results.\n",
    "            results.append({\"fc0_fc1\": fc0_fc1_result, \"fc1_fc0\": fc1_fc0_result})\n",
    "            print(results)\n",
    "\n",
    "            # Save results\n",
    "            output_path = f\"output/ex2/output-{FC0_PRUNE_RATE_STR}-{FC1_PRUNE_RATE_STR}.pkl\"\n",
    "            with open(output_path, 'wb') as f:\n",
    "                pkl.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
