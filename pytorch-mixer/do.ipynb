{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_loader(batch_size):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0], std=[1]),\n",
    "        transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0], std=[1]),\n",
    "        transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.MNIST(root=\"./data\",\n",
    "                                train=True,\n",
    "                                download=True,\n",
    "                                transform=transform_train)\n",
    "    testset = datasets.MNIST(root=\"./data\",\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "\n",
    "    train_sampler = RandomSampler(trainset)\n",
    "    test_sampler = SequentialSampler(testset)\n",
    "    train_loader = DataLoader(trainset,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=4,\n",
    "                              pin_memory=True)\n",
    "    test_loader = DataLoader(testset,\n",
    "                             sampler=test_sampler,\n",
    "                             batch_size=batch_size,\n",
    "                             num_workers=4,\n",
    "                             pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(28 * 28, 300)\n",
    "        self.fc1 = nn.Linear(300, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.dropout = nn.Dropout1d(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(0.5)\n",
    "model.load_state_dict(torch.load(\"lenet.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_hook(act, idx):\n",
    "    def hook(model, input, output):\n",
    "        act[idx] = output.detach().numpy()\n",
    "    return hook\n",
    "\n",
    "\n",
    "def add_hooks(model):\n",
    "    act = [None for _ in range(2)]\n",
    "    handles = [\n",
    "        model.fc0.register_forward_hook(get_activation_hook(act, 0)),\n",
    "        model.fc1.register_forward_hook(get_activation_hook(act, 1)),\n",
    "    ]\n",
    "    return act, handles\n",
    "\n",
    "\n",
    "def remove_hooks(handles):\n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "\n",
    "\n",
    "def get_activations(model, data):\n",
    "    act, handles = add_hooks(model)\n",
    "    _ = model(data)\n",
    "    remove_hooks(handles)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_acc(model):\n",
    "    _, test_loader = get_loader(60)\n",
    "    correct = 0\n",
    "    for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "        pred_y = torch.argmax(model(batch_x), axis=-1)\n",
    "        correct += torch.sum(torch.eq(pred_y, batch_y))\n",
    "\n",
    "    val_acc = correct / len(test_loader.dataset)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned neuron 14 with CKA = 0.9999995231628418, val_acc = 0.9757999777793884 and p = 0.01\n",
      "Pruned neuron 77 with CKA = 0.9999985694885254, val_acc = 0.9757999777793884 and p = 0.02\n",
      "Pruned neuron 10 with CKA = 0.9999975562095642, val_acc = 0.9757999777793884 and p = 0.03\n",
      "Pruned neuron 52 with CKA = 0.9999951720237732, val_acc = 0.9757999777793884 and p = 0.04\n",
      "Pruned neuron 85 with CKA = 0.9999721050262451, val_acc = 0.9757999777793884 and p = 0.05\n",
      "Pruned neuron 82 with CKA = 0.9999426007270813, val_acc = 0.9757999777793884 and p = 0.06\n",
      "Pruned neuron 11 with CKA = 0.9999054670333862, val_acc = 0.9757999777793884 and p = 0.07\n",
      "Pruned neuron 8 with CKA = 0.9998435378074646, val_acc = 0.9757000207901001 and p = 0.08\n",
      "Pruned neuron 62 with CKA = 0.9997838735580444, val_acc = 0.9757000207901001 and p = 0.09\n",
      "Pruned neuron 78 with CKA = 0.9997207522392273, val_acc = 0.9757000207901001 and p = 0.1\n",
      "Pruned neuron 88 with CKA = 0.9996231198310852, val_acc = 0.9757000207901001 and p = 0.11\n",
      "Pruned neuron 29 with CKA = 0.9995080828666687, val_acc = 0.9753999710083008 and p = 0.12\n",
      "Pruned neuron 48 with CKA = 0.9993723630905151, val_acc = 0.9754999876022339 and p = 0.13\n",
      "Pruned neuron 46 with CKA = 0.999255359172821, val_acc = 0.9753000140190125 and p = 0.14\n",
      "Pruned neuron 26 with CKA = 0.9991389513015747, val_acc = 0.9751999974250793 and p = 0.15\n",
      "Pruned neuron 12 with CKA = 0.9990200996398926, val_acc = 0.9747999906539917 and p = 0.16\n",
      "Pruned neuron 92 with CKA = 0.9989239573478699, val_acc = 0.9749000072479248 and p = 0.17\n",
      "Pruned neuron 43 with CKA = 0.9988663792610168, val_acc = 0.9750000238418579 and p = 0.18\n",
      "Pruned neuron 51 with CKA = 0.998783528804779, val_acc = 0.9746999740600586 and p = 0.19\n",
      "Pruned neuron 61 with CKA = 0.9986589550971985, val_acc = 0.9743000268936157 and p = 0.2\n",
      "Pruned neuron 32 with CKA = 0.998553991317749, val_acc = 0.9743000268936157 and p = 0.21\n",
      "Pruned neuron 23 with CKA = 0.9984160661697388, val_acc = 0.9736999869346619 and p = 0.22\n",
      "Pruned neuron 42 with CKA = 0.9983553886413574, val_acc = 0.972100019454956 and p = 0.23\n",
      "Pruned neuron 9 with CKA = 0.9983065724372864, val_acc = 0.9721999764442444 and p = 0.24\n",
      "Pruned neuron 17 with CKA = 0.9982707500457764, val_acc = 0.9724000096321106 and p = 0.25\n",
      "Pruned neuron 30 with CKA = 0.9981911778450012, val_acc = 0.9724000096321106 and p = 0.26\n",
      "Pruned neuron 15 with CKA = 0.9981176257133484, val_acc = 0.9722999930381775 and p = 0.27\n",
      "Pruned neuron 56 with CKA = 0.9979822039604187, val_acc = 0.9725000262260437 and p = 0.28\n",
      "Pruned neuron 3 with CKA = 0.9978179931640625, val_acc = 0.972599983215332 and p = 0.29\n",
      "Pruned neuron 97 with CKA = 0.9976631999015808, val_acc = 0.9728999733924866 and p = 0.3\n",
      "Pruned neuron 40 with CKA = 0.9975010752677917, val_acc = 0.9728999733924866 and p = 0.31\n",
      "Pruned neuron 28 with CKA = 0.9973431825637817, val_acc = 0.9729999899864197 and p = 0.32\n",
      "Pruned neuron 35 with CKA = 0.9972551465034485, val_acc = 0.9731000065803528 and p = 0.33\n",
      "Pruned neuron 45 with CKA = 0.9971746206283569, val_acc = 0.9728999733924866 and p = 0.34\n",
      "Pruned neuron 63 with CKA = 0.9970629215240479, val_acc = 0.9715999960899353 and p = 0.35\n",
      "Pruned neuron 80 with CKA = 0.9968589544296265, val_acc = 0.9715999960899353 and p = 0.36\n",
      "Pruned neuron 54 with CKA = 0.99666428565979, val_acc = 0.9713000059127808 and p = 0.37\n",
      "Pruned neuron 41 with CKA = 0.9964425563812256, val_acc = 0.9710000157356262 and p = 0.38\n",
      "Pruned neuron 25 with CKA = 0.9962975978851318, val_acc = 0.9717000126838684 and p = 0.39\n",
      "Pruned neuron 58 with CKA = 0.9960030317306519, val_acc = 0.9664999842643738 and p = 0.4\n",
      "Pruned neuron 65 with CKA = 0.9956938624382019, val_acc = 0.9664999842643738 and p = 0.41\n",
      "Pruned neuron 39 with CKA = 0.9954119920730591, val_acc = 0.9663000106811523 and p = 0.42\n",
      "Pruned neuron 79 with CKA = 0.9951909184455872, val_acc = 0.9642000198364258 and p = 0.43\n",
      "Pruned neuron 87 with CKA = 0.9950337409973145, val_acc = 0.9617999792098999 and p = 0.44\n",
      "Pruned neuron 5 with CKA = 0.9948477149009705, val_acc = 0.9620000123977661 and p = 0.45\n",
      "Pruned neuron 16 with CKA = 0.9946181178092957, val_acc = 0.9617999792098999 and p = 0.46\n",
      "Pruned neuron 20 with CKA = 0.994414746761322, val_acc = 0.9624999761581421 and p = 0.47\n",
      "Pruned neuron 69 with CKA = 0.9940882921218872, val_acc = 0.9632999897003174 and p = 0.48\n",
      "Pruned neuron 1 with CKA = 0.9937437772750854, val_acc = 0.9632999897003174 and p = 0.49\n",
      "Pruned neuron 50 with CKA = 0.9933644533157349, val_acc = 0.9624000191688538 and p = 0.5\n",
      "Pruned neuron 55 with CKA = 0.9929778575897217, val_acc = 0.961899995803833 and p = 0.51\n",
      "Pruned neuron 73 with CKA = 0.9925197958946228, val_acc = 0.9613999724388123 and p = 0.52\n",
      "Pruned neuron 44 with CKA = 0.99212247133255, val_acc = 0.9621000289916992 and p = 0.53\n",
      "Pruned neuron 98 with CKA = 0.991784930229187, val_acc = 0.9621999859809875 and p = 0.54\n",
      "Pruned neuron 37 with CKA = 0.9916169047355652, val_acc = 0.9617000222206116 and p = 0.55\n",
      "Pruned neuron 57 with CKA = 0.9915505051612854, val_acc = 0.9613999724388123 and p = 0.56\n",
      "Pruned neuron 72 with CKA = 0.9912897944450378, val_acc = 0.9599000215530396 and p = 0.57\n",
      "Pruned neuron 33 with CKA = 0.9911572337150574, val_acc = 0.9564999938011169 and p = 0.58\n",
      "Pruned neuron 27 with CKA = 0.990788996219635, val_acc = 0.9562000036239624 and p = 0.59\n",
      "Pruned neuron 34 with CKA = 0.9902759194374084, val_acc = 0.9562000036239624 and p = 0.6\n",
      "Pruned neuron 93 with CKA = 0.9896069765090942, val_acc = 0.9524999856948853 and p = 0.61\n",
      "Pruned neuron 38 with CKA = 0.9891840815544128, val_acc = 0.9531000256538391 and p = 0.62\n",
      "Pruned neuron 2 with CKA = 0.9892809391021729, val_acc = 0.9559999704360962 and p = 0.63\n",
      "Pruned neuron 31 with CKA = 0.9886900782585144, val_acc = 0.9557999968528748 and p = 0.64\n",
      "Pruned neuron 18 with CKA = 0.9881343245506287, val_acc = 0.9563000202178955 and p = 0.65\n",
      "Pruned neuron 67 with CKA = 0.9873732924461365, val_acc = 0.9563000202178955 and p = 0.66\n",
      "Pruned neuron 68 with CKA = 0.986536979675293, val_acc = 0.9563000202178955 and p = 0.67\n",
      "Pruned neuron 75 with CKA = 0.9855350255966187, val_acc = 0.954800009727478 and p = 0.68\n",
      "Pruned neuron 21 with CKA = 0.9842931628227234, val_acc = 0.9545999765396118 and p = 0.69\n",
      "Pruned neuron 24 with CKA = 0.9829224944114685, val_acc = 0.9534000158309937 and p = 0.7\n",
      "Pruned neuron 70 with CKA = 0.9816386103630066, val_acc = 0.9510999917984009 and p = 0.71\n",
      "Pruned neuron 13 with CKA = 0.9802156686782837, val_acc = 0.949999988079071 and p = 0.72\n",
      "Pruned neuron 49 with CKA = 0.9798480868339539, val_acc = 0.9491999745368958 and p = 0.73\n",
      "Pruned neuron 74 with CKA = 0.9801775217056274, val_acc = 0.9448000192642212 and p = 0.74\n",
      "Pruned neuron 36 with CKA = 0.97954261302948, val_acc = 0.9429000020027161 and p = 0.75\n",
      "Pruned neuron 94 with CKA = 0.9783779978752136, val_acc = 0.9516000151634216 and p = 0.76\n",
      "Pruned neuron 83 with CKA = 0.9766289591789246, val_acc = 0.9505000114440918 and p = 0.77\n",
      "Pruned neuron 66 with CKA = 0.9749176502227783, val_acc = 0.9488999843597412 and p = 0.78\n",
      "Pruned neuron 81 with CKA = 0.9723948240280151, val_acc = 0.9484000205993652 and p = 0.79\n",
      "Pruned neuron 7 with CKA = 0.9697772264480591, val_acc = 0.9448999762535095 and p = 0.8\n",
      "Pruned neuron 95 with CKA = 0.966964066028595, val_acc = 0.9470000267028809 and p = 0.81\n",
      "Pruned neuron 89 with CKA = 0.964134156703949, val_acc = 0.9297999739646912 and p = 0.82\n",
      "Pruned neuron 90 with CKA = 0.960757851600647, val_acc = 0.9264000058174133 and p = 0.83\n",
      "Pruned neuron 6 with CKA = 0.9583570957183838, val_acc = 0.925000011920929 and p = 0.84\n",
      "Pruned neuron 22 with CKA = 0.9555456638336182, val_acc = 0.8942999839782715 and p = 0.85\n",
      "Pruned neuron 99 with CKA = 0.9517883062362671, val_acc = 0.8942000269889832 and p = 0.86\n",
      "Pruned neuron 76 with CKA = 0.9445174336433411, val_acc = 0.8456000089645386 and p = 0.87\n",
      "Pruned neuron 59 with CKA = 0.9378857016563416, val_acc = 0.7652999758720398 and p = 0.88\n",
      "Pruned neuron 64 with CKA = 0.9312947392463684, val_acc = 0.5691999793052673 and p = 0.89\n",
      "Pruned neuron 84 with CKA = 0.9234587550163269, val_acc = 0.5703999996185303 and p = 0.9\n",
      "Pruned neuron 19 with CKA = 0.9191113710403442, val_acc = 0.4352000057697296 and p = 0.91\n",
      "Pruned neuron 86 with CKA = 0.9055594801902771, val_acc = 0.4219000041484833 and p = 0.92\n",
      "Pruned neuron 96 with CKA = 0.8868927955627441, val_acc = 0.3418999910354614 and p = 0.93\n",
      "Pruned neuron 4 with CKA = 0.8616160750389099, val_acc = 0.3407000005245209 and p = 0.94\n",
      "Pruned neuron 60 with CKA = 0.8345727324485779, val_acc = 0.328900009393692 and p = 0.95\n",
      "Pruned neuron 47 with CKA = 0.8093557953834534, val_acc = 0.3212999999523163 and p = 0.96\n",
      "Pruned neuron 91 with CKA = 0.7747082710266113, val_acc = 0.2393999993801117 and p = 0.97\n",
      "Pruned neuron 0 with CKA = 0.6439666748046875, val_acc = 0.2085999995470047 and p = 0.98\n",
      "Pruned neuron 71 with CKA = 0.4720599949359894, val_acc = 0.2085999995470047 and p = 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calvin/Documents/URI/CSC561/csc561-final/pytorch-mixer/CKA_Google.py:94: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  return scaled_hsic / (normalization_x * normalization_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned neuron 53 with CKA = nan, val_acc = 0.11349999904632568 and p = 1.0\n",
      "[tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9757), tensor(0.9757), tensor(0.9757), tensor(0.9757), tensor(0.9754), tensor(0.9755), tensor(0.9753), tensor(0.9752), tensor(0.9748), tensor(0.9749), tensor(0.9750), tensor(0.9747), tensor(0.9743), tensor(0.9743), tensor(0.9737), tensor(0.9721), tensor(0.9722), tensor(0.9724), tensor(0.9724), tensor(0.9723), tensor(0.9725), tensor(0.9726), tensor(0.9729), tensor(0.9729), tensor(0.9730), tensor(0.9731), tensor(0.9729), tensor(0.9716), tensor(0.9716), tensor(0.9713), tensor(0.9710), tensor(0.9717), tensor(0.9665), tensor(0.9665), tensor(0.9663), tensor(0.9642), tensor(0.9618), tensor(0.9620), tensor(0.9618), tensor(0.9625), tensor(0.9633), tensor(0.9633), tensor(0.9624), tensor(0.9619), tensor(0.9614), tensor(0.9621), tensor(0.9622), tensor(0.9617), tensor(0.9614), tensor(0.9599), tensor(0.9565), tensor(0.9562), tensor(0.9562), tensor(0.9525), tensor(0.9531), tensor(0.9560), tensor(0.9558), tensor(0.9563), tensor(0.9563), tensor(0.9563), tensor(0.9548), tensor(0.9546), tensor(0.9534), tensor(0.9511), tensor(0.9500), tensor(0.9492), tensor(0.9448), tensor(0.9429), tensor(0.9516), tensor(0.9505), tensor(0.9489), tensor(0.9484), tensor(0.9449), tensor(0.9470), tensor(0.9298), tensor(0.9264), tensor(0.9250), tensor(0.8943), tensor(0.8942), tensor(0.8456), tensor(0.7653), tensor(0.5692), tensor(0.5704), tensor(0.4352), tensor(0.4219), tensor(0.3419), tensor(0.3407), tensor(0.3289), tensor(0.3213), tensor(0.2394), tensor(0.2086), tensor(0.2086), tensor(0.1135)]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "from cka_heatmap import compute_heatmap, display_heatmap, cka_linear\n",
    "\n",
    "model = LeNet(0.5)\n",
    "model.load_state_dict(torch.load(\"lenet.model\"))\n",
    "\n",
    "parameters_to_prune = (\n",
    "    # (model.fc0, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    # (model.fc2, 'weight'),\n",
    ")\n",
    "\n",
    "train_loader, _ = get_loader(60)\n",
    "data = next(iter(train_loader))[0]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    act = get_activations(model, data)\n",
    "    for module, name in parameters_to_prune:\n",
    "        neurons = module.weight.shape[0]\n",
    "        accs = []\n",
    "        for i in range(neurons):\n",
    "            cka_and_neuron = []\n",
    "            for neuron in range(neurons):\n",
    "                neuron_weight = torch.clone(module.weight[neuron])\n",
    "                if neuron_weight.sum() == 0: # TODO: not really right\n",
    "                    continue\n",
    "                module.weight[neuron] = 0\n",
    "                pruned_act = get_activations(model, data)\n",
    "                module.weight[neuron] = neuron_weight\n",
    "                cka = cka_linear(act[1], pruned_act[1])\n",
    "                cka_and_neuron.append((cka, neuron))\n",
    "                # print(module.weight)\n",
    "            # print(cka_and_neuron)\n",
    "            cka, neuron = max(cka_and_neuron)\n",
    "            module.weight[neuron] = 0\n",
    "            val_acc = get_val_acc(model)\n",
    "            accs.append(val_acc)\n",
    "            print(f\"Pruned neuron {neuron} with CKA = {cka}, val_acc = {val_acc} and p = {(i + 1) / neurons}\")\n",
    "        print(accs)\n",
    "\n",
    "    # prune.ln_structured(module, name=name, amount=0.5, n=1, dim=0)\n",
    "    # print(module.weight.sum())\n",
    "    # prune.ln_structured(module, name=name, amount=0.5, n=1, dim=0)\n",
    "    # print(module.weight.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.01\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.02\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.03\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.04\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.05\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.06\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.07\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.08\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.09\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.1\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.11\n",
      "Pruned with L1 norm with val_acc = 0.9757000207901001 and p = 0.12\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.13\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.14\n",
      "Pruned with L1 norm with val_acc = 0.9761000275611877 and p = 0.15\n",
      "Pruned with L1 norm with val_acc = 0.9761000275611877 and p = 0.16\n",
      "Pruned with L1 norm with val_acc = 0.9761000275611877 and p = 0.17\n",
      "Pruned with L1 norm with val_acc = 0.9763000011444092 and p = 0.18\n",
      "Pruned with L1 norm with val_acc = 0.9763000011444092 and p = 0.19\n",
      "Pruned with L1 norm with val_acc = 0.9761000275611877 and p = 0.2\n",
      "Pruned with L1 norm with val_acc = 0.9758999943733215 and p = 0.21\n",
      "Pruned with L1 norm with val_acc = 0.9758999943733215 and p = 0.22\n",
      "Pruned with L1 norm with val_acc = 0.9758999943733215 and p = 0.23\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.24\n",
      "Pruned with L1 norm with val_acc = 0.9758999943733215 and p = 0.25\n",
      "Pruned with L1 norm with val_acc = 0.9761999845504761 and p = 0.26\n",
      "Pruned with L1 norm with val_acc = 0.9761000275611877 and p = 0.27\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.28\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.29\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.3\n",
      "Pruned with L1 norm with val_acc = 0.9758999943733215 and p = 0.31\n",
      "Pruned with L1 norm with val_acc = 0.975600004196167 and p = 0.32\n",
      "Pruned with L1 norm with val_acc = 0.9757999777793884 and p = 0.33\n",
      "Pruned with L1 norm with val_acc = 0.9753999710083008 and p = 0.34\n",
      "Pruned with L1 norm with val_acc = 0.9753999710083008 and p = 0.35\n",
      "Pruned with L1 norm with val_acc = 0.9753000140190125 and p = 0.36\n",
      "Pruned with L1 norm with val_acc = 0.9750000238418579 and p = 0.37\n",
      "Pruned with L1 norm with val_acc = 0.9746000170707703 and p = 0.38\n",
      "Pruned with L1 norm with val_acc = 0.9732999801635742 and p = 0.39\n",
      "Pruned with L1 norm with val_acc = 0.9731000065803528 and p = 0.4\n",
      "Pruned with L1 norm with val_acc = 0.9728999733924866 and p = 0.41\n",
      "Pruned with L1 norm with val_acc = 0.9728999733924866 and p = 0.42\n",
      "Pruned with L1 norm with val_acc = 0.9724000096321106 and p = 0.43\n",
      "Pruned with L1 norm with val_acc = 0.9725000262260437 and p = 0.44\n",
      "Pruned with L1 norm with val_acc = 0.9722999930381775 and p = 0.45\n",
      "Pruned with L1 norm with val_acc = 0.9714999794960022 and p = 0.46\n",
      "Pruned with L1 norm with val_acc = 0.9713000059127808 and p = 0.47\n",
      "Pruned with L1 norm with val_acc = 0.97079998254776 and p = 0.48\n",
      "Pruned with L1 norm with val_acc = 0.9704999923706055 and p = 0.49\n",
      "Pruned with L1 norm with val_acc = 0.9704999923706055 and p = 0.5\n",
      "Pruned with L1 norm with val_acc = 0.970300018787384 and p = 0.51\n",
      "Pruned with L1 norm with val_acc = 0.9703999757766724 and p = 0.52\n",
      "Pruned with L1 norm with val_acc = 0.9699000120162964 and p = 0.53\n",
      "Pruned with L1 norm with val_acc = 0.9699000120162964 and p = 0.54\n",
      "Pruned with L1 norm with val_acc = 0.9610000252723694 and p = 0.55\n",
      "Pruned with L1 norm with val_acc = 0.9609000086784363 and p = 0.56\n",
      "Pruned with L1 norm with val_acc = 0.9607999920845032 and p = 0.57\n",
      "Pruned with L1 norm with val_acc = 0.9585000276565552 and p = 0.58\n",
      "Pruned with L1 norm with val_acc = 0.9571999907493591 and p = 0.59\n",
      "Pruned with L1 norm with val_acc = 0.9580000042915344 and p = 0.6\n",
      "Pruned with L1 norm with val_acc = 0.9570000171661377 and p = 0.61\n",
      "Pruned with L1 norm with val_acc = 0.9527000188827515 and p = 0.62\n",
      "Pruned with L1 norm with val_acc = 0.9532999992370605 and p = 0.63\n",
      "Pruned with L1 norm with val_acc = 0.9532999992370605 and p = 0.64\n",
      "Pruned with L1 norm with val_acc = 0.9531999826431274 and p = 0.65\n",
      "Pruned with L1 norm with val_acc = 0.9521999955177307 and p = 0.66\n",
      "Pruned with L1 norm with val_acc = 0.9523000121116638 and p = 0.67\n",
      "Pruned with L1 norm with val_acc = 0.9517999887466431 and p = 0.68\n",
      "Pruned with L1 norm with val_acc = 0.9517999887466431 and p = 0.69\n",
      "Pruned with L1 norm with val_acc = 0.9508000016212463 and p = 0.7\n",
      "Pruned with L1 norm with val_acc = 0.949999988079071 and p = 0.71\n",
      "Pruned with L1 norm with val_acc = 0.9513999819755554 and p = 0.72\n",
      "Pruned with L1 norm with val_acc = 0.9517999887466431 and p = 0.73\n",
      "Pruned with L1 norm with val_acc = 0.9498999714851379 and p = 0.74\n",
      "Pruned with L1 norm with val_acc = 0.9503999948501587 and p = 0.75\n",
      "Pruned with L1 norm with val_acc = 0.9451000094413757 and p = 0.76\n",
      "Pruned with L1 norm with val_acc = 0.9366000294685364 and p = 0.77\n",
      "Pruned with L1 norm with val_acc = 0.8762000203132629 and p = 0.78\n",
      "Pruned with L1 norm with val_acc = 0.8319000005722046 and p = 0.79\n",
      "Pruned with L1 norm with val_acc = 0.829200029373169 and p = 0.8\n",
      "Pruned with L1 norm with val_acc = 0.8148999810218811 and p = 0.81\n",
      "Pruned with L1 norm with val_acc = 0.7953000068664551 and p = 0.82\n",
      "Pruned with L1 norm with val_acc = 0.8431000113487244 and p = 0.83\n",
      "Pruned with L1 norm with val_acc = 0.8413000106811523 and p = 0.84\n",
      "Pruned with L1 norm with val_acc = 0.8349999785423279 and p = 0.85\n",
      "Pruned with L1 norm with val_acc = 0.8206999897956848 and p = 0.86\n",
      "Pruned with L1 norm with val_acc = 0.7731000185012817 and p = 0.87\n",
      "Pruned with L1 norm with val_acc = 0.7440000176429749 and p = 0.88\n",
      "Pruned with L1 norm with val_acc = 0.7394000291824341 and p = 0.89\n",
      "Pruned with L1 norm with val_acc = 0.7156000137329102 and p = 0.9\n",
      "Pruned with L1 norm with val_acc = 0.6739000082015991 and p = 0.91\n",
      "Pruned with L1 norm with val_acc = 0.6638000011444092 and p = 0.92\n",
      "Pruned with L1 norm with val_acc = 0.6021999716758728 and p = 0.93\n",
      "Pruned with L1 norm with val_acc = 0.5200999975204468 and p = 0.94\n",
      "Pruned with L1 norm with val_acc = 0.391400009393692 and p = 0.95\n",
      "Pruned with L1 norm with val_acc = 0.37880000472068787 and p = 0.96\n",
      "Pruned with L1 norm with val_acc = 0.2906000018119812 and p = 0.97\n",
      "Pruned with L1 norm with val_acc = 0.2727000117301941 and p = 0.98\n",
      "Pruned with L1 norm with val_acc = 0.11410000175237656 and p = 0.99\n",
      "Pruned with L1 norm with val_acc = 0.11349999904632568 and p = 1.0\n",
      "[tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9757), tensor(0.9758), tensor(0.9758), tensor(0.9761), tensor(0.9761), tensor(0.9761), tensor(0.9763), tensor(0.9763), tensor(0.9761), tensor(0.9759), tensor(0.9759), tensor(0.9759), tensor(0.9758), tensor(0.9759), tensor(0.9762), tensor(0.9761), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9759), tensor(0.9756), tensor(0.9758), tensor(0.9754), tensor(0.9754), tensor(0.9753), tensor(0.9750), tensor(0.9746), tensor(0.9733), tensor(0.9731), tensor(0.9729), tensor(0.9729), tensor(0.9724), tensor(0.9725), tensor(0.9723), tensor(0.9715), tensor(0.9713), tensor(0.9708), tensor(0.9705), tensor(0.9705), tensor(0.9703), tensor(0.9704), tensor(0.9699), tensor(0.9699), tensor(0.9610), tensor(0.9609), tensor(0.9608), tensor(0.9585), tensor(0.9572), tensor(0.9580), tensor(0.9570), tensor(0.9527), tensor(0.9533), tensor(0.9533), tensor(0.9532), tensor(0.9522), tensor(0.9523), tensor(0.9518), tensor(0.9518), tensor(0.9508), tensor(0.9500), tensor(0.9514), tensor(0.9518), tensor(0.9499), tensor(0.9504), tensor(0.9451), tensor(0.9366), tensor(0.8762), tensor(0.8319), tensor(0.8292), tensor(0.8149), tensor(0.7953), tensor(0.8431), tensor(0.8413), tensor(0.8350), tensor(0.8207), tensor(0.7731), tensor(0.7440), tensor(0.7394), tensor(0.7156), tensor(0.6739), tensor(0.6638), tensor(0.6022), tensor(0.5201), tensor(0.3914), tensor(0.3788), tensor(0.2906), tensor(0.2727), tensor(0.1141), tensor(0.1135)]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    act = get_activations(model, data)\n",
    "    for _, name in parameters_to_prune:\n",
    "        neurons = module.weight.shape[0]\n",
    "        accs = []\n",
    "        for i in range(neurons):\n",
    "            model = LeNet(0.5)\n",
    "            model.load_state_dict(torch.load(\"lenet.model\"))\n",
    "            model.eval()\n",
    "            prune.ln_structured(model.fc1, name, amount=((i + 1) / neurons), n=1, dim=0)\n",
    "            val_acc = get_val_acc(model)\n",
    "            accs.append(val_acc)\n",
    "            print(f\"Pruned with L1 norm with val_acc = {val_acc} and p = {(i + 1) / neurons}\")\n",
    "        print(accs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tensor = lambda x: x\n",
    "cka_prune = [tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9757), tensor(0.9757), tensor(0.9757), tensor(0.9757), tensor(0.9754), tensor(0.9755), tensor(0.9753), tensor(0.9752), tensor(0.9748), tensor(0.9749), tensor(0.9750), tensor(0.9747), tensor(0.9743), tensor(0.9743), tensor(0.9737), tensor(0.9721), tensor(0.9722), tensor(0.9724), tensor(0.9724), tensor(0.9723), tensor(0.9725), tensor(0.9726), tensor(0.9729), tensor(0.9729), tensor(0.9730), tensor(0.9731), tensor(0.9729), tensor(0.9716), tensor(0.9716), tensor(0.9713), tensor(0.9710), tensor(0.9717), tensor(0.9665), tensor(0.9665), tensor(0.9663), tensor(0.9642), tensor(0.9618), tensor(0.9620), tensor(0.9618), tensor(0.9625), tensor(0.9633), tensor(0.9633), tensor(0.9624), tensor(0.9619), tensor(0.9614), tensor(0.9621), tensor(0.9622), tensor(0.9617), tensor(0.9614), tensor(0.9599), tensor(0.9565), tensor(0.9562), tensor(0.9562), tensor(0.9525), tensor(0.9531), tensor(0.9560), tensor(0.9558), tensor(0.9563), tensor(0.9563), tensor(0.9563), tensor(0.9548), tensor(0.9546), tensor(0.9534), tensor(0.9511), tensor(0.9500), tensor(0.9492), tensor(0.9448), tensor(0.9429), tensor(0.9516), tensor(0.9505), tensor(0.9489), tensor(0.9484), tensor(0.9449), tensor(0.9470), tensor(0.9298), tensor(0.9264), tensor(0.9250), tensor(0.8943), tensor(0.8942), tensor(0.8456), tensor(0.7653), tensor(0.5692), tensor(0.5704), tensor(0.4352), tensor(0.4219), tensor(0.3419), tensor(0.3407), tensor(0.3289), tensor(0.3213), tensor(0.2394), tensor(0.2086), tensor(0.2086), tensor(0.1135)]\n",
    "l1_prune = [tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9757), tensor(0.9758), tensor(0.9758), tensor(0.9761), tensor(0.9761), tensor(0.9761), tensor(0.9763), tensor(0.9763), tensor(0.9761), tensor(0.9759), tensor(0.9759), tensor(0.9759), tensor(0.9758), tensor(0.9759), tensor(0.9762), tensor(0.9761), tensor(0.9758), tensor(0.9758), tensor(0.9758), tensor(0.9759), tensor(0.9756), tensor(0.9758), tensor(0.9754), tensor(0.9754), tensor(0.9753), tensor(0.9750), tensor(0.9746), tensor(0.9733), tensor(0.9731), tensor(0.9729), tensor(0.9729), tensor(0.9724), tensor(0.9725), tensor(0.9723), tensor(0.9715), tensor(0.9713), tensor(0.9708), tensor(0.9705), tensor(0.9705), tensor(0.9703), tensor(0.9704), tensor(0.9699), tensor(0.9699), tensor(0.9610), tensor(0.9609), tensor(0.9608), tensor(0.9585), tensor(0.9572), tensor(0.9580), tensor(0.9570), tensor(0.9527), tensor(0.9533), tensor(0.9533), tensor(0.9532), tensor(0.9522), tensor(0.9523), tensor(0.9518), tensor(0.9518), tensor(0.9508), tensor(0.9500), tensor(0.9514), tensor(0.9518), tensor(0.9499), tensor(0.9504), tensor(0.9451), tensor(0.9366), tensor(0.8762), tensor(0.8319), tensor(0.8292), tensor(0.8149), tensor(0.7953), tensor(0.8431), tensor(0.8413), tensor(0.8350), tensor(0.8207), tensor(0.7731), tensor(0.7440), tensor(0.7394), tensor(0.7156), tensor(0.6739), tensor(0.6638), tensor(0.6022), tensor(0.5201), tensor(0.3914), tensor(0.3788), tensor(0.2906), tensor(0.2727), tensor(0.1141), tensor(0.1135)]\n",
    "\n",
    "plt.plot(list(range(1, 101)), cka_prune, label=\"cka\")\n",
    "plt.plot(list(range(1, 101)), l1_prune, label=\"l1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
